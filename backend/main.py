import sys
import os
import logging
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

from fastapi import FastAPI
from fastapi.staticfiles import StaticFiles
from fastapi.middleware.cors import CORSMiddleware
from backend.search import search_router
# from backend.local_myllm import llm_router
from backend.gpt import gpt_router  # GPT-3.5 Turbo
from backend.recommend import recommend_router
from backend.image_processing import image_router
from backend.chain import chat_router

# ë¡œê¹…
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

app = FastAPI(title="ê´‘ìš´ëŒ€í•™êµ ì±—ë´‡ API", version="1.0")

# CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # ngrok ë° ë¡œì»¬ í…ŒìŠ¤íŠ¸ ì§€ì›
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# API ì—”ë“œí¬ì¸íŠ¸ ë“±ë¡
app.include_router(search_router, prefix="/api/search")
# app.include_router(llm_router, prefix="/api/llm")  # ê¸°ì¡´ Ollama ê¸°ë°˜ API (ë¹„í™œì„±í™”)
app.include_router(gpt_router, prefix="/api/chat")  # OpenAI GPT ê¸°ë°˜ API
app.include_router(image_router, prefix="/api/image")
app.include_router(recommend_router, prefix="/api/recommend")
app.include_router(chat_router, prefix="/api/chat")

# í—¬ìŠ¤ ì²´í¬ API
@app.get("/api/health")
async def health_check():
    return {"status": "OK"}

# í”„ë¡ íŠ¸ì—”ë“œ ì •ì  íŒŒì¼ ì œê³µ (Next.js ì •ì  ì‚¬ì´íŠ¸)
app.mount("/", StaticFiles(directory="frontend/out", html=True), name="static")

# FastAPI ì‹¤í–‰
if __name__ == "__main__":
    import uvicorn
    logger.info("ğŸš€ FastAPI ì„œë²„ ì‹œì‘...")
    uvicorn.run(app, host="0.0.0.0", port=20005, timeout_keep_alive=300, reload=True)
